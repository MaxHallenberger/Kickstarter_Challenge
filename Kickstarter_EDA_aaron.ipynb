{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .csv files and concat them into one dataframe\n",
    "original_dataframe = pd.concat(map(pd.read_csv, glob.glob('data/*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working dataframe, so that we don't have to wait 10s it to import again if we want to start fresh\n",
    "df = original_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "EDA - Part 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a very limited amount of suspended projects (drop), canceled projects will be treated as though they failed\n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate projects and store them in a table\n",
    "dups = df.groupby(df.id.tolist()).size().reset_index().rename(columns={0:'count'})\n",
    "# Sum the final col of that table, and subtract the number of culprits:\n",
    "dups['count'].sum() - dups.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features which will not be needed for further analysis\n",
    "dropped_features = ['blurb', 'currency_symbol', 'backers_count', 'is_backing', 'permissions', 'is_starred', 'source_url',\n",
    "                    'slug', 'name', 'static_usd_rate', 'profile', 'friends', 'spotlight', 'is_starrable', 'photo', 'pledged', 'usd_type',\n",
    "                    'fx_rate', 'location', 'creator', 'currency_trailing_code','current_currency', 'created_at', 'urls']\n",
    "df = df.drop(dropped_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built array which contains live projects for later use \n",
    "array_live = ['live']\n",
    "live_projects = df.loc[df['state'].isin(array_live)]\n",
    "\n",
    "# Filter and concat. for target variable\n",
    "array_notlive = ['successful', 'failed', 'canceled']\n",
    "finished_projects = df.loc[df['state'].isin(array_notlive)]\n",
    "finished_projects.replace('canceled','failed', inplace=True)\n",
    "# Replace successful and failed entries\n",
    "finished_projects.replace(['successful','failed'],[1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by 'date_changed_at' so that we will keep the entry that was most recently updated\n",
    "df.sort_values('state_changed_at')\n",
    "# Remove duplicates\n",
    "duplicates = df.duplicated(subset='id', keep='last')\n",
    "df = df[~duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract category names from long string in 'category' column\n",
    "list = []\n",
    "for i, j in df['category'].iteritems():\n",
    "    try:\n",
    "        found = re.search('slug\":\"(.+?)/', j).group(1)\n",
    "        list.append(found)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "list_2 = []\n",
    "for i, j in enumerate(list):\n",
    "    try:\n",
    "        found = re.search('(.+?)\"', j).group(1)\n",
    "        list_2.append(found)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Add the categories and delete the original cluttered category\n",
    "df['categories'] = pd.Series(list_2)\n",
    "df.drop('category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new column with readable timeformat\n",
    "df['launched_at_new'] = pd.to_datetime(df['launched_at'], unit='s')\n",
    "df['deadline_new'] = pd.to_datetime(df['deadline'], unit='s')\n",
    "df['state_changed_at_new'] = pd.to_datetime(df['state_changed_at'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature 'duration' that displays wheather the project timespan was more or less than 30 days\n",
    "df_time = df.eval('duration = deadline - launched_at')\n",
    "df_time['duration'] = ['over' if x > 2592000 else 'under' for x in df_time['duration']]\n",
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dates to weekend(1) or weekday(0)\n",
    "def change_time(dataframe, column_list):\n",
    "    for column in column_list:\n",
    "        #dataframe[column] = pd.to_datetime(dataframe[column], unit='s')\n",
    "        dataframe[column] = [1 if x >= 6 else 0 for x in pd.to_datetime(dataframe[column], unit='s').dt.weekday]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_lst = ['launched_at', 'deadline', 'state_changed_at']\n",
    "change_time(df_time, times_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column 'time' that displays the time from project launch to project end\n",
    "df_time.eval('time = state_changed_at_new - launched_at_new', inplace=True)\n",
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time['time'] = pd.to_datetime(df_time['time']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='time', data=df_time, hue='state')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91d869ccaeca790aa5051b91a32a203614f98fb4ba9d9ad287b8f5d4ebac826d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
