{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kickstarer](./images/kickstarter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .csv files and concat them into one dataframe\n",
    "original_dataframe = pd.concat(map(pd.read_csv, glob.glob('data/*.csv')))\n",
    "# Reset the indices\n",
    "original_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a working dataframe, so that we don't have to wait 10s it to import again if we want to start fresh\n",
    "df = original_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "EDA - Part 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a very limited amount of suspended projects (drop), canceled projects will be treated as though they failed\n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate projects and store them in a table\n",
    "dups = df.groupby(df.id.tolist()).size().reset_index().rename(columns={0:'count'})\n",
    "# Sum the final col of that table, and subtract the number of culprits:\n",
    "dups['count'].sum() - dups.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features which will not be needed for further analysis\n",
    "dropped_features = ['blurb', 'currency_symbol', 'backers_count', 'is_backing', 'permissions', 'is_starred', 'source_url',\n",
    "                    'slug', 'name', 'static_usd_rate', 'profile', 'friends', 'spotlight', 'is_starrable', 'photo', 'pledged', 'usd_type',\n",
    "                    'fx_rate', 'location', 'creator', 'currency_trailing_code','current_currency', 'created_at', 'urls', 'disable_communication', 'usd_pledged' ]\n",
    "df = df.drop(dropped_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built array which contains live projects for later use \n",
    "array_live = ['live']\n",
    "live_projects = df.loc[df['state'].isin(array_live)]\n",
    "\n",
    "# Filter and concat. for target variable\n",
    "array_notlive = ['successful', 'failed', 'canceled']\n",
    "df = df.loc[df['state'].isin(array_notlive)]\n",
    "df.replace('canceled','failed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace successful and failed entries\n",
    "df.replace(['successful','failed'],[1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by 'date_changed_at' so that we will keep the entry that was most recently updated\n",
    "df.sort_values('state_changed_at')\n",
    "# Remove duplicates\n",
    "duplicates = df.duplicated(subset='id', keep='last')\n",
    "df = df[~duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract category names from long string in 'category' column\n",
    "list = []\n",
    "for i, j in df['category'].iteritems():\n",
    "    try:\n",
    "        found = re.search('slug\":\"(.+?)/', j).group(1)\n",
    "        list.append(found)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "list_2 = []\n",
    "for i, j in enumerate(list):\n",
    "    try:\n",
    "        found = re.search('(.+?)\"', j).group(1)\n",
    "        list_2.append(found)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Add the categories and delete the original cluttered category\n",
    "df['categories'] = pd.Series(list_2)\n",
    "df.drop('category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new column with readable timeformat\n",
    "df['launched_at_new'] = pd.to_datetime(df['launched_at'], unit='s')\n",
    "df['deadline_new'] = pd.to_datetime(df['deadline'], unit='s')\n",
    "df['state_changed_at_new'] = pd.to_datetime(df['state_changed_at'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature 'duration' that displays wheather the project timespan was more or less than 30 days\n",
    "df = df.eval('duration = deadline - launched_at')\n",
    "df['duration'] = ['over' if x > 2592000 else 'under' for x in df['duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column 'time' that displays the time from project launch to project end\n",
    "df.eval('time = state_changed_at_new - launched_at_new', inplace=True)\n",
    "# Convert to days\n",
    "df['time'] = df['time'].apply(lambda x: pd.Timedelta(x).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dates to weekend(1) or weekday(0)\n",
    "def change_time(dataframe, column_list):\n",
    "    for column in column_list:\n",
    "        dataframe[column] = [1 if x >= 6 else 0 for x in pd.to_datetime(dataframe[column], unit='s').dt.weekday]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_lst = ['launched_at', 'deadline', 'state_changed_at']\n",
    "change_time(df, times_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "EDA - Part 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data needs to be plotted categorical and which numerical\n",
    "categorical = ['country','currency', 'staff_pick', 'categories','duration']\n",
    "numerical = ['usd_pledged', 'goal', 'converted_pledged_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df, column):\n",
    "    \"\"\"Generates barplots of categorical data\n",
    "\n",
    "    Args:\n",
    "        df (pd dataframe): Dataframe\n",
    "        column (object): list of names of columns which should be plotted\n",
    "    \"\"\"\n",
    "    # get feature\n",
    "    for i in column:\n",
    "        varValue = df[i].value_counts()\n",
    "\n",
    "        plt.figure(figsize = (12,3))\n",
    "        plt.bar(varValue.index, varValue, color = '#87c442', edgecolor = 'black')\n",
    "        plt.xticks(varValue.index, varValue.index.values)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(i.capitalize())\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df, categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data needs to be plotted categorical and which numerical\n",
    "numerical = ['goal', 'converted_pledged_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['goal'] = df[np.abs(df.goal-df.goal.mean()) <= (3*df.goal.std())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,3))\n",
    "plt.hist(df['goal'], bins = None, facecolor = '#87c442', edgecolor = 'black', range = [0.0,200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,3))\n",
    "plt.hist(df['converted_pledged_amount'], bins = None, facecolor = '#87c442', edgecolor = 'black', range = [0.0,200000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id (not needed anymore)\n",
    "df.drop('id', axis = 1, inplace = True)\n",
    "# Drop disable communication as well, only false values\n",
    "# Drop usd_pledged\n",
    "\n",
    "# Replace successful and failed entries\n",
    "df.replace(['successful','failed'],[1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode all categorical data (country, currency, staff_pick, categories, disable_communication, duration) boolean values might \n",
    "# need to be changed to 0,1 in column; includes: duration, disable_communication, staff_pick\n",
    "one_hot_featurelist = ['country', 'currency', 'staff_pick', 'categories', 'duration']\n",
    "one_hot = pd.get_dummies(df[one_hot_featurelist])\n",
    "df.drop(one_hot_featurelist, axis = 1, inplace=True)\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns(df, column):\n",
    "    \"\"\"Function that scales the data with a min_max scaler\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Dataframe\n",
    "        column (object): Name or list of names including the columns which should be normalized\n",
    "\n",
    "    Returns:\n",
    "        Dataframe object: Returns the dataframe including the normalized columns\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    for i in column:\n",
    "        scaler.fit(df[[i]])\n",
    "        df[i] = scaler.transform(df[[i]])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical data\n",
    "nummerical = ['goal','converted_pledged_amount','usd_pledged']\n",
    "df = scale_columns(df, nummerical)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91d869ccaeca790aa5051b91a32a203614f98fb4ba9d9ad287b8f5d4ebac826d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
