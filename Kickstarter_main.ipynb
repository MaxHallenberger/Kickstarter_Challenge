{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kickstarer](./images/kickstarter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly.offline import iplot\n",
    "import plotly.tools as tls\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "\n",
    "import time\n",
    "import json\n",
    "from functions_kickstarter import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .csv files and concat them into one dataframe\n",
    "df = pd.concat(map(pd.read_csv, glob.glob('data/*.csv')))\n",
    "# Reset the indices\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### EDA - Part 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# 35 targets, some of them appear to have large amounts on NaN values, object bool and int mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# Friends, is_backing, is_starred, and permission have a lot of NaN values, can probably be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a very limited amount of suspended projects (drop), canceled projects will be treated as though they failed\n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Data Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate projects and store them in a table // Remove duplicates\n",
    "dups = df.groupby(df.id.tolist()).size().reset_index().rename(columns={0:'count'})\n",
    "# Sum the final col of that table, and subtract the number of culprits:\n",
    "dups['count'].sum() - dups.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by 'date_changed_at' so that we will keep the entry that was most recently updated\n",
    "df.sort_values('state_changed_at')\n",
    "# Remove duplicates\n",
    "duplicates = df.duplicated(subset='id', keep='last')\n",
    "df = df[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features which will not be needed for further analysis, most of those features are either meaningless (ex. urls), have next to no entries (ex. friends), or are bad for predictions\n",
    "# See Target.md for a full list of explanation\n",
    "dropped_features = ['blurb', 'currency_symbol', 'backers_count', 'is_backing', 'permissions', 'is_starred', 'source_url',\n",
    "                    'slug', 'name', 'profile', 'friends', 'spotlight', 'is_starrable', 'photo', 'pledged', 'usd_type',\n",
    "                    'fx_rate', 'location', 'creator', 'currency_trailing_code','current_currency', 'created_at', 'disable_communication']\n",
    "df = df.drop(dropped_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We limit our dataset to goals below 1 Million, values above are treated as outliers\n",
    "df = df.query('goal < 1000000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract category from category column\n",
    "df['category'] = df['category'].apply(lambda x: json.loads(x)['slug'])\n",
    "df['category'] = df['category'].apply(lambda x: x.split('/',)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new column with readable timeformat\n",
    "df['launched_at'] = pd.to_datetime(df['launched_at'], unit='s')\n",
    "\n",
    "df['state_changed_at'] = pd.to_datetime(df['state_changed_at'], unit='s')\n",
    "# Add the deadline date as date column\n",
    "df['deadline'] = pd.to_datetime(df['deadline'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column 'time' that displays the time from project launch to project end\n",
    "#df.eval('time = state_changed_at - launched_at', inplace=True)                                 /////\n",
    "df.eval('duration = deadline - launched_at', inplace=True)\n",
    "# Convert to days\n",
    "#df['time'] = df['time'].apply(lambda x: pd.Timedelta(x).days)                                  /////\n",
    "df['duration'] = df['duration'].apply(lambda x: pd.Timedelta(x).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the goal converted to one currency (usd)\n",
    "df.eval('goal = goal * static_usd_rate', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that displays the month of launch\n",
    "df['launched_at'] = df['launched_at'].apply(lambda x: pd.to_datetime(x, unit='s')).dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### EDA - Part 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data for bar plots\n",
    "categorical = ['country','currency', 'staff_pick', 'category']\n",
    "bar_plot(df, categorical)\n",
    "# Takeaways: By far the most projects are from the US, Staff Picks are only rarely used, most projects are sized between 0 and 20k Dollar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,3))\n",
    "plt.hist(df['goal'], color = '#87c442', edgecolor = 'black',range = [0, 20000])\n",
    "plt.ylabel('# of Projects')\n",
    "plt.xlabel('USD')\n",
    "plt.title('Goal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_st= df.groupby('state')['state'].count()\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = ['#FF9999', '#FFC000', '#8FD9B6', '#D395D0']\n",
    "explode= [0.05,0.05,0.1,0.05,0.05]\n",
    "plt.pie(cnt_st.values,labels=cnt_st.index.values,\n",
    "        autopct='%.1f%%',\n",
    "        explode=explode,\n",
    "        shadow=False,\n",
    "        colors=sns.color_palette('BuGn', 4),#(‘bright’)[0:5],\n",
    "        textprops={'fontsize':15})\n",
    "plt.title('Pie chart : Projects\\' States',fontsize=20,fontweight='bold')\n",
    "plt.legend(loc='upper right', fontsize=11)\n",
    "\n",
    "# Takeaway: About half of the projects succeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kick = df.loc[df['state'].isin(['failed','successful'])]\n",
    "df_failed = df_kick[df_kick['state'] == 'failed'].sample(10000, replace=True)\n",
    "df_sucess = df_kick[df_kick['state'] == 'successful'].sample(10000, replace=True)\n",
    "#First plot\n",
    "trace0 = go.Histogram(\n",
    "    x= np.log(df_kick.goal + 1),\n",
    "    histnorm='probability', marker=dict(color='#229954'), showlegend=False,\n",
    "    xbins=dict(\n",
    "        start=-5.0,\n",
    "        end=19.0,\n",
    "        size=1),\n",
    "    autobiny=True)\n",
    "#Second plot\n",
    "trace1 = go.Histogram(\n",
    "    x = np.log(df_kick.usd_pledged + 1),\n",
    "    histnorm='probability', marker=dict(color='#0B5345'), showlegend=False,\n",
    "    xbins=dict(\n",
    "        start=-1.0,\n",
    "        end=17.0,\n",
    "        size=1))\n",
    "# Add histogram data\n",
    "failed = np.log(df_failed['goal']+1)\n",
    "success = np.log(df_sucess['goal']+1)\n",
    "trace3 = go.Histogram(\n",
    "    x=failed,\n",
    "    opacity=0.60, nbinsx=30, name='Goals Failed', histnorm='probability', marker=dict(color='#2ECC71')\n",
    ")\n",
    "trace4 = go.Histogram(\n",
    "    x=success,\n",
    "    opacity=0.60, nbinsx=30, name='Goals Sucessful', histnorm='probability', marker=dict(color='#145A32')\n",
    ")\n",
    "data = [trace0, trace1, trace3, trace4]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "#Creating the grid\n",
    "fig = plotly.tools.make_subplots(rows=2, cols=2, specs=[ [{'colspan': 2}, None], [{}, {}]],\n",
    "                          subplot_titles=('Failed and Sucessful Projects',\n",
    "                                          'Goal','Pledged'))\n",
    "#setting the figs\n",
    "fig.append_trace(trace0, 2, 1)\n",
    "fig.append_trace(trace1, 2, 2)\n",
    "fig.append_trace(trace3, 1, 1)\n",
    "fig.append_trace(trace4, 1, 1)\n",
    "fig['layout'].update(title='Distribuitions',\n",
    "                     height=500, width=900, barmode='overlay')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kick2 = df.loc[df['state'].isin(['failed','successful'])]\n",
    "main_cats = df_kick2['category'].value_counts()\n",
    "main_cats_failed = df_kick2[df_kick2['state'] == 'failed']['category'].value_counts()\n",
    "main_cats_sucess = df_kick2[df_kick2['state'] == 'successful']['category'].value_counts()\n",
    "#First plot\n",
    "trace0 = go.Bar(\n",
    "    x=main_cats_failed.index,\n",
    "    y=main_cats_failed.values,\n",
    "    name='Failed Categories', marker=dict(color='#ABEBC6')\n",
    ")\n",
    "#Second plot\n",
    "trace1 = go.Bar(\n",
    "    x=main_cats_sucess.index,\n",
    "    y=main_cats_sucess.values,\n",
    "    name='Success Categories', marker=dict(color='#2ECC71')\n",
    ")\n",
    "#Third plot\n",
    "trace2 = go.Bar(\n",
    "    x=main_cats.index,\n",
    "    y=main_cats.values,\n",
    "    name='Categories Distributiion', marker=dict(color='#145A32')\n",
    ")\n",
    "#Creating the grid\n",
    "fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                          subplot_titles=('Failed','Sucessful', \"General Category's\"))\n",
    "#setting the figs\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "z=[12,24,48]\n",
    "fig['layout'].update(showlegend=True,\n",
    "                     title=\"Main Category's Distribuition\",\n",
    "                     bargap=0.05, height = 600, width = 800)\n",
    "iplot(fig)\n",
    "\n",
    "# Takeaway Tech seems to have a high failure rate but is quite succesful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_live = ['live']\n",
    "live_projects = df.loc[df['state'].isin(array_live)]\n",
    "# Filter and concat. for target variable\n",
    "array_notlive = ['successful', 'failed', 'canceled']\n",
    "df = df.loc[df['state'].isin(array_notlive)]\n",
    "# Add canceled to failed projects\n",
    "df.replace('canceled','failed', inplace=True)\n",
    "# Replace successful and failed entries with 0 and 1\n",
    "#df.replace(['successful','failed'],[1,0], inplace=True)\n",
    "df_new=df.groupby('staff_pick')['state'].value_counts(normalize=True)\n",
    "df_new =df_new.mul(100).rename('Percent').reset_index()\n",
    "g = sns.catplot(x='state', y='Percent', hue='staff_pick', kind='bar', data=df_new, palette=sns.color_palette(['#222222', '#05ce78']))\n",
    "g.fig.set_size_inches(15,10)\n",
    "g.ax.set_ylim(0,100)\n",
    "g.set_xlabels('State',fontsize=25)\n",
    "g.set_ylabels('Percentage in %',fontsize=25)\n",
    "g.set(title='Staff Pick Influence on Success of Projects')\n",
    "#sns.set(font_scale = 2)\n",
    "plt.legend(fontsize='small', title_fontsize='25')\n",
    "for p in g.ax.patches:\n",
    "    txt = str(p.get_height().round(1)) + '%'\n",
    "    txt_x = p.get_x()\n",
    "    txt_y = p.get_height()\n",
    "    g.ax.text(txt_x, txt_y,txt)\n",
    "\n",
    "# Takeaway: There seems to be a strong influence on the projects success depending on a staff pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Feature Engineering - Part 2\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns and set aside live projects for later predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside columns for later use on predicted live projects\n",
    "list = ['urls','state','staff_pick']\n",
    "alive_feature_list = df[list]\n",
    "\n",
    "# Extract urls from web dict\n",
    "alive_feature_list['urls'] = alive_feature_list['urls'].apply(lambda x: json.loads(x)['web'])\n",
    "# Only take those values where state is equal to live state\n",
    "array_live = ['live']\n",
    "alive_feature_list = alive_feature_list.loc[alive_feature_list['state'].isin(array_live)]\n",
    "# Drop state again\n",
    "alive_feature_list.drop('state', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id (not needed anymore), converted pledged amount/usd_pledged (predictor not av. at the beginning of a project),\n",
    "# country (redundant with currency), drop staff_pick bc we dont know the staff pick when we make predictions\n",
    "drop_list = ['id','converted_pledged_amount', 'usd_pledged', 'country', 'urls', 'static_usd_rate', 'staff_pick', 'state_changed_at', 'deadline']\n",
    "df.drop(drop_list, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode all categorical data (currency, categories)\n",
    "one_hot_featurelist = ['currency', 'category', 'launched_at']\n",
    "one_hot = pd.get_dummies(df[one_hot_featurelist])\n",
    "df.drop(one_hot_featurelist, axis = 1, inplace=True)\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization and Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical data according to a min-max scaler\n",
    "numerical = ['goal']\n",
    "df = scale_columns(df, numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract live values\n",
    "array_live = ['live']\n",
    "ongoing_projects = df.loc[df['state'].isin(array_live)]\n",
    "\n",
    "# Filter target variable\n",
    "array_notlive = ['successful', 'failed', 'canceled']\n",
    "\n",
    "df = df.loc[df['state'].isin(array_notlive)]\n",
    "# Add canceled to failed projects\n",
    "df.replace('canceled','failed', inplace=True)\n",
    "# Replace successful and failed entries with 0 and 1\n",
    "df.replace(['successful','failed'],[1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Modelling\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x and y\n",
    "X = df.drop('state', axis = 1)\n",
    "y = df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dummy classifier predicts with a 53% precision if a project will succeed or fail\n",
    "dummy = DummyClassifier(strategy='stratified', random_state=RSEED, constant=None)\n",
    "dummy.fit(X,y)\n",
    "\n",
    "y_pred = dummy.predict(X)\n",
    "precision_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3, random_state=RSEED)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models used\n",
    "models = []\n",
    "\n",
    "models.append(LogisticRegression())\n",
    "models.append(DecisionTreeClassifier())\n",
    "models.append(RandomForestClassifier())\n",
    "models.append(GradientBoostingClassifier())\n",
    "models.append(AdaBoostClassifier(DecisionTreeClassifier(),learning_rate=0.1))\n",
    "models.append(KNeighborsClassifier())\n",
    "models.append(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of volding for cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cross validation scores from list of models. The target is f1. Time is also accounted for to find the most effective models\n",
    "cv_results = []\n",
    "cv_names = []\n",
    "cv_times = []\n",
    "\n",
    "for model in models:\n",
    "    start_time = time.time()\n",
    "    print('go:', model)\n",
    "    cv_results.append(cross_val_score(model, X_train, y = y_train, scoring = \"precision\", cv = kfold, n_jobs=4, verbose=0))\n",
    "    cv_names.append(model.__class__.__name__)\n",
    "    end_time = time.time()\n",
    "    total_time = round(end_time - start_time ,2)\n",
    "    cv_times.append(total_time)\n",
    "    print('end:', model)\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "    \n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":cv_names, \"Time needed for training\":cv_times})\n",
    "\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res,orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Average precision\")\n",
    "g = g.set_title(\"K-fold Cross validation average precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res['criterion'] = cv_res.CrossValMeans - cv_res.CrossValerrors/2\n",
    "cv_res.sort_values(by='criterion', ascending=False)\n",
    "# We select XGBClassifier, and RandomForestClassifier for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGB classifier\n",
    "\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "max_depth = [1,2,4,8,10]\n",
    "min_child_weight = np.linspace(1, 10, 5, endpoint=True) \n",
    "\n",
    "gamma = np.linspace(0.5, 5, 5, endpoint=True)\n",
    "subsample = np.linspace(0.5, 1, 5, endpoint=True)\n",
    "colsample_bytree = np.linspace(0.5, 1, 5, endpoint=True)\n",
    "\n",
    "XGB_param_grid = {\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'gamma': gamma,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'max_depth': max_depth\n",
    "        }\n",
    "\n",
    "\n",
    "gsXGB = HalvingGridSearchCV(estimator = XGB, \n",
    "                    param_grid = XGB_param_grid, cv=kfold, scoring=\"precision\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsXGB.fit(X_train,y_train)\n",
    "\n",
    "XGB_best = gsXGB.best_estimator_\n",
    "print(XGB_best.get_params())\n",
    "\n",
    "# Best score\n",
    "gsXGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 800, num = 2)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 20, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [ 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": max_depth,\n",
    "              \"max_features\": max_features,\n",
    "              \"min_samples_split\": min_samples_split,\n",
    "              \"min_samples_leaf\": min_samples_leaf,\n",
    "              \"bootstrap\": bootstrap,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": [\"gini\"]}\n",
    "              \n",
    "\n",
    "gsRFC = HalvingGridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"precision\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train,y_train)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "print(RFC_best.get_params())\n",
    "\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier (soft voting) including the three best models after grid search\n",
    "votingC = VotingClassifier(estimators=[ ('XGB',XGB_best), (\"RandomForest\",RFC_best)], voting='soft', n_jobs=4)\n",
    "# Fit train data to Voting Classifier\n",
    "votingC = votingC.fit(X_train, y_train)\n",
    "# Make predictions on test data\n",
    "votingC_predict = votingC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array for the probability of all classes ordered by the label of classes\n",
    "votingC_predict_proba = votingC.predict_proba(X_test)\n",
    "\n",
    "# Precision Score on test data\n",
    "precision_score(votingC_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cfm = confusion_matrix(votingC_predict, y_test)\n",
    "sns.heatmap(cfm, cmap='YlGnBu', annot=True, fmt='d', linewidths=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of y_test data\n",
    "y_test_use = y_test.reset_index().drop('index', axis=1)\n",
    "\n",
    "# Get a dataframe with the prediction probabilities\n",
    "votingC_predict_proba = pd.DataFrame(votingC_predict_proba)\n",
    "\n",
    "# Replace column headers with Failed, Successful strings\n",
    "votingC_predict_proba = votingC_predict_proba.rename({0: 'Failed', 1: 'Successful'}, axis='columns')\n",
    "\n",
    "# Add the real y_test data\n",
    "votingC_predict_proba['y_test'] = y_test_use\n",
    "\n",
    "# Replace 0's and 1's in the y_test column\n",
    "votingC_predict_proba['y_test'] = votingC_predict_proba['y_test'].map({1: 'Successful', 0: 'Failed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of the prediction probabilities of the violin plot against the true values 'y' of our test set\n",
    "ax = sns.catplot(x=\"y_test\", y=\"Successful\", data=votingC_predict_proba, kind=\"violin\", palette=sns.color_palette(['#6d7b75', '#05ce78']), linewidth = 2,\n",
    "                inner = \"quartile\")\n",
    "ax.set(xlabel='True Outcome', ylabel='Predicted Probability to Succeed')\n",
    "ax.fig.set_size_inches(15,12)\n",
    "sns.set(font_scale = 2)\n",
    "plt.axhline(0.5, color = 'black', linestyle = '--')\n",
    "ax.set(title='Predicted Probability vs. True Outcome')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions on live dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x for live datasets by dropping the state\n",
    "X_array_live = ongoing_projects.drop('state', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use live set to predict the probabilities of success\n",
    "votingC_predict_proba_live = votingC.predict_proba(X_array_live)\n",
    "votingC_predict_proba_live = pd.DataFrame(votingC_predict_proba_live)\n",
    "votingC_predict_proba_live = votingC_predict_proba_live.rename({0: 'Failed', 1: 'Successful'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "ongoing_projects_pred = votingC.predict(X_array_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions on alive projects\n",
    "alive_feature_list['prediction'] = ongoing_projects_pred.tolist()\n",
    "# Replace 1, 0 entries with successful and failed\n",
    "alive_feature_list['prediction']  = alive_feature_list['prediction'].replace([1,0], ['successful','failed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index for concatination\n",
    "alive_feature_list = alive_feature_list.reset_index().drop('index', axis=1)\n",
    "# Concat the feature list with the probabilities for the live Kickstarter Projects to succeed\n",
    "predictions_live = pd.concat([alive_feature_list, votingC_predict_proba_live], axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c3da8c6bea62d9f4fc19eef1fc0b50de29df54557cb61f4a10eef6c4e8e8582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
